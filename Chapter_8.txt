Fostering Dissent




Helicopter gunner Ron Ridenhour began to hear the “dark and bloody” rumors in late April 1968. Hanging around U.S. headquarters in Vietnam, Ridenhour ran into a buddy he had met during aviation training. His friend had a disturbing story to tell. About a month earlier, troops belonging to Charlie Company had conducted what should have been an ordinary strike on a suspected Vietcong stronghold. But when they choppered into the village of My Lai, something went terribly awry.1

To their surprise, the soldiers found only a tiny settlement—trees, huts, and farm animals—occupied not by enemy combatants but by women, children, and men too old to fight. In the hours that followed, American troops slaughtered the defenseless villagers. Large numbers of Vietnamese civilians were mercilessly killed, mown down by machine guns, executed with pistols, or blown up by grenades thrown into their homes. Some estimates said that more than five hundred people died in My Lai. The hamlet was burned to the ground.

Shocked, Ridenhour had trouble believing what he had heard. But over the course of the next year, he pieced together bits of the story from soldiers who had been part of Charlie Company themselves or who knew men who were. The details he heard were horrible and horribly consistent. He assembled the facts as best he could, and upon his return to the United States at the end of his tour of duty, Ridenhour wrote it all down in a letter. He sent his letter to thirty people, including members of Congress, the president, and officials at the Pentagon:

Exactly what did, in fact, occur in the village of [My Lai] in March 1968 I do not know for certain, but I am convinced it was very black indeed. I remain irrevocably persuaded that if you and I do truly believe in the principles of justice and the equality of every man, however humble, before the law, that form the very backbone that this country is founded on, then we must press forward a widespread and public investigation of this matter with all our combined efforts.2



Ridenhour’s letter triggered an internal investigation by the army that resulted in several indictments. Ultimately only one man, Lieutenant William Calley, was convicted of crimes committed in My Lai. When the American public became aware of the massacre and the evidence that it had been covered up, the stories divided the country. Public support for the war in Vietnam was further eroded. But at the same time, many people reacted angrily to Ron Ridenhour and to other whistleblowers for taking actions they saw as unpatriotic treachery that undermined the troops. In 1974, six years after the slaughter in My Lai, William Calley, the only person ever held accountable, was pardoned by President Richard Nixon.

Ron Ridenhour went on to become an esteemed investigative journalist. Later reflecting on his experience uncovering the atrocities committed by soldiers at My Lai, he wrote, “The question most often put to me was not why they had done it, but why I had done it.”3

In this chapter, we explain how social identities motivate people to express dissent. Although most people assume that good group members comply with social norms and suppress criticism of their groups, our research suggests that the deepest form of group loyalty often involves the expression of disagreement when people think it is necessary to salvage the values and goals of their in-group.





A Right and a Duty


Among nations, America is a country that knows the value of civil disobedience, which makes the negative reactions elicited by dissenters and whistleblowers like Ron Ridenhour all the more surprising. From the Boston Tea Party to the civil rights movement, protest is part of the American DNA. The publication of the Declaration of Independence in 1776 founded the United States in a blazing act of dissent, upholding rebellion as not just a right but a duty:

We hold these truths to be self-evident, that all men are created equal, that they are endowed by their Creator with certain unalienable Rights, that among these are Life, Liberty and the pursuit of Happiness…But when a long train of abuses and usurpations…evinces a design to reduce them under absolute Despotism, it is their right, it is their duty, to throw off such Government, and to provide new Guards for their future security.



The Congress of the original thirteen colonies may have had King George III in mind, but their words went on to influence independence movements well into the twentieth century as peoples around the world sought to overthrow rulers and colonizers they came to regard as illegitimate.

At home, these words have inspired generations of American citizens to question the status quo and challenge authority. In what was probably his most influential speech, civil rights leader Martin Luther King Jr. drew extensively on the Declaration of Independence, declaring: “I still have a dream. It is deeply rooted in the American dream. I have a dream that one day this nation will rise up, live out the true meaning of its creed: We hold these truths to be self-evident, that all men are created equal.”

Just as Ron Ridenhour linked his protest to the country’s founding backbone, King grounded political protest for the rights of Black Americans in the nation’s original principles. What King and Ridenhour both understood was that the costs of dissent were necessary to advance the values embodied in the founding documents of their nation. In both cases, they were willing to pay a high price—from loathing to assassination—to ensure the country lived up to its creed.





Punishing Moral Rebels


Certain truths may be self-evident, but the value of dissent is not one of them. It turns out that the merits of critics and the righteousness of rebels are in the eye of the beholder. It is easy when one is on the outside of a situation or looking back from the vantage of history to hold dissenters and whistleblowers in high esteem, even to regard them as heroes. But these people may seem something else entirely when one is faced with them in the present. In real life and in our own groups, they are often troublemakers, rabble-rousers, deviants, freaks, and all-around pains in the neck.

Americans now celebrate a national holiday in honor of Martin Luther King Jr. during which politicians, companies, and public figures of all kinds pay homage to his words and legacy. By 2011, MLK was almost universally perceived as a hero, and his national favorability rating was 94 percent. But during the civil rights era itself, opinions of MLK were sharply divided. In 1966, three years after he delivered his “I Have a Dream” speech, only 33 percent of Americans saw him as a positive figure.4

The fact is that in the present, people are often uncomfortable with “moral rebels”—people who live up to their values in the face of significant obstacles.

Benoît Monin and his colleagues have studied the mixed responses people often have to individuals doing the right thing.5 In one experiment, for example, people learned about a prior participant who had been asked to write and record a speech in which she would have to publicly express an opinion that was contrary to her personal beliefs. Participants then had the chance to listen to what the earlier participant had recorded. One set of participants heard someone obediently doing the experimenter’s bidding, articulating views that were not her own. However, another set of participants instead heard someone refusing to go along, disavowing any intention of saying things that she did not believe.

An act of agreeable obedience on the one hand and an act of principled disobedience on the other. If you were a participant yourself, which of these people would you have more respect for? If you are anything like us, you quite confidently assume that you would prefer the principled rebel.

But would you? Would we?

What we have not told you was that before they learned about anyone else, half of the participants in each of the conditions had also been asked to write and record their own speeches, and these participants had, to a person, complied with the experimenter’s request to express an opinion with which they disagreed. The other half of the participants had received no such request and were thus simply uninvolved observers of another person’s obedience or disobedience.

The uninvolved observers liked and respected the person they heard being rebellious more than the person they heard being obedient. They were impressed by someone willing to stand up for what she believed. If you came to the same conclusion, it is likely because you, the reader, were uninvolved.

But for those participants who had themselves been obedient, the pattern was completely reversed. They liked and respected the obedient speech giver more than the rebellious refuser.

In subsequent experiments, people learned about someone who had refused to complete a task on the grounds that it was probably racist. Critically, participants again learned about the rebel after they either had or had not completed the potentially racist task themselves. When asked to name a trait that they thought described this rebellious fellow subject, uninvolved observers (whose own behavior was not at stake) said that the moral rebel who had refused to complete the racist task was “strong-minded,” “independent,” “decisive,” or “fair-minded.” But participants who had already done the task themselves described the same rebel as “self-righteous,” “defensive,” “easily offended,” or “confused.” Why the difference?

From a distance, we admire moral rebels. But when they shake our belief that we are inherently good and virtuous people ourselves, it alters our perspective. In these instances, moral rebels make us look bad to ourselves and others, and we fear these more virtuous individuals will judge us negatively.

Who among us has not seen or heard about someone behaving unethically or immorally under pressure—perhaps cheating clients because the boss demanded it or bullying a coworker because everyone found it funny—and thought, I would never do that! And yet, at least some of the time, many of us do go along with things that we disagree with. By disobeying while others remain compliant, rebels expose the fact that many people often do not do the right thing when faced with a moral quandary. People do not acknowledge or maybe even realize their limitations until someone more courageous makes them aware of their own moral frailty. Self-righteous jerk! they think.

It turns out that people do not necessarily appreciate do-gooders, even when they are objectively doing good for their groups. It is not surprising that people react negatively to freeloaders, the sort of people who contribute little to a difficult group project but take plenty of credit when the project is successful or the kind who avoid paying taxes but draw heavily on government services. What is more startling, however, is that people can be just as negative toward highly generous group members.

Researchers Craig Parks and Asako Stone looked at people’s responses to individuals who contributed a lot to a group resource but took little from it for themselves.6 They found that when offered the opportunity to get rid of some group members, people were just as eager to expel these generous individuals as they were to kick out selfish ones!

When the researchers asked people why they reacted this way, some said that it was because the generous group member made them look bad by comparison. But a second type of explanation also emerged, one grounded in the sense that the generous person was breaking with group norms. Participants wrote, “It’s strange for someone to keep giving and not take much in return. If you give a lot you should use a lot.” And: “I probably would have been okay with him if I hadn’t seen everyone else’s choices and saw he was so different. He’s too different from the rest of us.”

In the scientific literature on how people respond to dissenters, rebels, and critics, it turns out there are a variety of things that trigger negative reactions. The thread that unites them is that they threaten people’s identities. Sometimes, as with the moral rebels we discussed above, the threat is to group members’ personal sense of self, but very often it is to their social identities and to what they believe are the interests and norms of the group.

People defend their group norms because these norms define them and help coordinate action; they get everyone on the same page. For this reason, deviants tend to be rejected more strongly in smaller groups, where they might do more damage to norms or dilute a consensus.7

Norm violators are judged particularly harshly when their actions blur the boundaries between groups, muddying the distinctions that members like to uphold between “us” and “them.” Groups also tend not to appreciate deviance or dissent when they are under the pressure of a deadline or are embroiled in competition with an out-group.8 A little divergence can be a healthy thing, but this is not the moment! When the group is at war, it’s time to keep your mouth shut and rally around the flag. You are either with us or against us!

But groups that quash dissent are playing a dangerous game. Over time, embracing a diversity of opinions and listening to criticism is necessary for groups to flourish in the face of new challenges and adversity. Groups and organizations that demand too cultlike a conformity, like the ones we discussed in chapter 3, are often doomed to failure, sooner or later.





Why We Need Dissent


To properly understand the merits of dissent, criticism, and rebellion, it is clear we can’t entirely rely on the opinions of people in the immediate situation. Fortunately, there is a sizable scientific literature on both the virtues and the downsides of dissent.

Charlan Nemeth, professor and author of the book In Defense of Troublemakers, has devoted much of her career to investigating the effects of dissent. She argues that the real benefits of dissenters come less from the ideas they espouse or suggestions they make than from the ways they change how the rest of us think.9

When people are exposed to popularly held ideas, their thinking tends to be lazy and narrow, focused on whether or not the majority view is correct. But when they hear a minority point of view, a rarer perspective, their thinking expands. They start to ponder why anyone would endorse that idea. Truth be told, they often start to argue against it, but in doing so they are forced to cast a wider net of thought, considering and perhaps even questioning their own assumptions.

This is critical because this is how dissent can improve innovation, creativity, and group decision-making. Dissent is effective because it changes the ways that other people think. This means that dissenters do not actually have to be right to benefit the group—they just have to speak up enough to get others thinking. Their mere presence can spark more divergent thought and open up space for others to express alternative views.

To measure the impact of dissent, researchers at the University of Michigan experimentally manipulated the presence or absence of dissenters in teams of students working together during the course of a semester.10 Over ten weeks, twenty-eight teams engaged in problem-solving tasks and were evaluated on the originality of their solutions. The stakes were quite high for the students, as these problems were worth 40 percent of their final grades.

In half of the teams, one of the five members had, unbeknownst to the rest, been recruited by the research team to serve as a dissenter. This allowed the researchers to determine if the inclusion of a single dissenter within the team would improve performance or just create conflict and slow the team down.

The researchers did not blindly select these rebels. They needed people to whom divergence came reasonably naturally and who would be comfortable expressing disagreement. Thus, the fourteen dissenters were people who had, on a prior questionnaire, endorsed statements like “I expect to take risks with regard to expressing my ideas in my group” and “I value novelty in human behavior.” The researchers provided some training, encouraging these students to be consistent and persistent when they dissented but not to appear rigid. They also asked them to express disagreement with their groups only when they really disagreed.

At the end of the semester, the results came in.

Adding a single dissenter to a small group paid off in several ways. Teams that were randomly assigned to include a dissenter performed better than those without. Their work was evaluated as more original by objective outside experts. Even the students working with dissenters noticed a difference. When they considered their own groups’ patterns of thinking, they rated them as more divergent than students in groups without dissenters.

Similar processes play out in companies and organizations. In a study of seven Fortune 500 companies, organizational researchers used detailed case studies to examine how top leadership teams functioned at two points in time: during periods when they were successful and periods when they were widely perceived to be failing to satisfy key stakeholders.11 The dynamics of the leadership teams were dramatically different during periods of success and failure.

The importance of shared identity was clearly associated with the successful periods. In these times, leadership teams appeared to have stronger feelings of “common fate,” were more committed to solving group problems, showed more team spirit, and were more focused on shared goals.

Critically, these organizations also encouraged more dissent in private meetings and members were more open and candid with one another during successful periods. This reveals that dissent can flourish along with a strong sense of shared identity and a feeling of team spirit. In fact, those factors seem to be important parts of the recipe for group success in both the lab and the real world.

Research suggests that dissent is most likely to be effective when it is persistent and consistent. In the classic film Twelve Angry Men, starring Henry Fonda, a jury considers the guilt or innocence of an eighteen-year-old man accused of killing his father. The evidence seems clear and in an initial secret ballot, eleven of the twelve jurors are ready to vote guilty. One juror wants to wrap things up quickly because he has tickets to a baseball game.

Only one—juror number eight—thinks that the accused man might be innocent and that the evidence is not as solid as it seems. Over the course of the next few hours, his observations and doubts slowly begin to change the minds of the other jurors, who themselves start to question the evidence. There are holdouts at first. But eventually the last proponent of a guilty verdict gives in. The jurors unanimously declare the young man not guilty.

The film is a rousing tale about the duty of dissent and about how a single, persistent skeptic can change the minds of others and alter the course of justice. More generally, it is the willingness of dissenters to stand their ground in the face of opposition that causes others to think more carefully. This person must really believe what they are saying, we think. Why is that?

As with everything involving human beings, however, the full story of dissent is a complicated one. Dissent does not have uniformly positive consequences for groups, and across studies the findings are mixed. In a recent meta-analysis, Codou Samba and colleagues found that strategic dissent among top management teams was associated with lower-quality decisions and lower performance.12 This happened because it seemed to worsen relationships among team members and actually reduced their careful consideration of information.

Importantly, however, what these researchers refer to as strategic dissent reflects not just disagreement about how a group or organization should go about achieving its goals but about what those very goals should be. In the case of leadership teams, this conflict reflects a fracturing at the top of an organization about what they are trying to achieve and potentially who they are. As Samba and colleagues put it, “Strategic dissent does not so much capture diversity of information and insights that can be fruitfully integrated, but instead represents conflicting goals and preferences that members have a vested interest in defending. Strategic dissent, thus, disrupts information elaboration because managers are motivated to defend their positions rather than engage in an open-minded search and analysis.”13

During their successful periods, the seven Fortune 500 companies mentioned earlier had elevated levels of dissent, but they also had palpable team spirit and were focused on shared goals. In the context of a clearly shared identity, dissent is beneficial. For teams that lack a shared identity or whose identity is seriously called into question, dissent is more challenging and difficult and may not always be associated immediately with better decisions or performance.

This is not to say that these disagreements are unimportant. Sometimes it is vital that groups—whether at the top of a management hierarchy or in society more broadly—debate and overhaul their goals, fundamentally reshaping who they are and what they stand for. But this process is unlikely to be easy.

To capitalize on the potential benefits of dissent, groups have to clear two hurdles: they have to have members willing to express divergent views, and the other members have to be able and willing to listen with curiosity rather than defensiveness. Both of these responses are grounded in strong and secure identities.





Are People Sheeple?


Although dissent, deviance, criticism, and rabble-rousing are clearly important, scientists have sunk much more of their time and energy into understanding their flip sides: conformity, compliance, and obedience. Psychologists’ “conformist” focus on conformity can be traced to two key events in the discipline’s history.

One was the conformity experiments conducted by Solomon Asch in which people went along with the erroneous judgments of other people despite the evidence of their own eyes.14 As we described in chapter 2, participants in these studies were given an exceedingly easy visual task to solve: identifying which of several lines were the same in length. Everyone could do the task just fine until people answering ahead of them started to give wrong answers. Suddenly participants were confronted with pressure to conform, which they gave into about a third of the time, answering the questions incorrectly themselves to go along with the crowd.

The second major event was a series of studies conducted a few years later by Yale psychologist Stanley Milgram.15 Milgram expanded on Asch’s conformity findings by examining how a single powerful person might shape behavior when the stakes were much higher than estimating lines.

He recruited residents of New Haven, Connecticut, for an experiment on how punishment affects learning. Participants arrived at Yale University in pairs and were met by an experimenter in a lab coat. Just like Asch, Milgram staged the situation so that only one member of each pair was there as a true subject—the other was secretly working for the research team. The real participants were all assigned to be the “teacher” in the experiment; they were told they would be testing the memory of a partner who was assigned to be the “learner.”

The teacher was asked to read lists of word pairs to the learner, who then had to recite them back. The twist was that every time the learner made a mistake, the teacher had to deliver an escalating electric shock as punishment for the error. The shocks started small at fifteen volts but increased by fifteen volts with every mistake. As the study progressed and the learner made more errors, the required voltages were labeled with increasingly forbidding warnings: INTENSE SHOCK, DANGER SEVERE SHOCK, and finally just XXX at 450 volts.

When these shocks were delivered by the teacher, the learner had been instructed to emit more and more intense complaints, expressions of pain, and requests to stop before falling ominously silent. If the teacher protested, the experimenter would respond firmly: “Please continue,” “The experiment requires you to continue,” “It is absolutely essential that you continue,” and, finally, “You have absolutely no choice but to continue.” In reality, of course, there were no shocks, and the whole scenario was an elaborate ruse.

Would you shock a complete stranger despite hearing him scream in agony or complain of heart problems? Most people say they would not.

Before conducting his experiment, Stanley Milgram asked a group of psychiatrists how they thought people would react when instructed to administer apparently dangerous shocks to a fellow participant. The clinicians’ consensus was that only one person in a thousand would be fully compliant.

The experts were wildly wrong. In the standard version of the experiment, nearly two thirds of participants fully obeyed the instructions of the experimenter. A sizable majority of people delivered the maximum level of shock to an apparently unconscious learner simply because they had been instructed to do so by a man wearing a lab coat.

In neither Asch’s nor Milgram’s studies were people happy about the situation they found themselves in. Asch’s participants appeared confused as they tried to figure out what on earth was going on. How can everyone else be mistaken? Is something wrong with my eyes? Many of Milgram’s participants questioned the experimenter. Are you sure? Shouldn’t we check on him? To which the experimenter responded implacably, “Please continue, the experiment must go on.” And many of them did go on to the very end, shocking an apparently helpless man in the room next door over and over again.

Initially, the results of these studies were hugely surprising and provocative to people. They illuminated aspects of human behavior that few expected. Many people saw parallels between Milgram’s experiments and the atrocities of the Holocaust. But ideas change, and these findings quickly went from shocking revelations to common wisdom, at least among social scientists. The lessons from Asch and Milgram seemed clear. People are highly conformist; they are sheeplike in the face of even mild pressure from peers. People are also blindly obedient to authority, and this unthinking compliance might lead them to participate in great evil.

In textbooks and popular-psychology books, these are often still the lessons drawn from these studies. But expert understanding of these issues has continued to evolve, and social scientists interpret them differently today. The lessons of these classic studies are more nuanced and complex—and might even surprise people who learned about these studies long ago. In each case, the story has much more to do with social identities than was previously understood.





We’re Not Sheep After All


As graduate students at the University of Toronto, the two of us spent many happy hours perusing secondhand bookstores in the Annex, a bustling neighborhood adjoining the downtown campus. Procrastinating on our dissertation work, we could convince ourselves that we were being productive by diligently checking out the psychology section in each store. Idly gazing at the shelves one day, Dom spotted a copy of Obedience to Authority, the book in which Stanley Milgram comprehensively described his obedience studies, a steal at $6.99. He snapped it up.

It is often safe to assume that the more famous a piece of research is, the less likely it is that people have actually read the original account. Over a million students take an introduction to psychology class each year, and most of them learn the textbook version of Milgram’s studies. After enough retellings, the studies become like myths—the key findings are amplified while critical details and context are slowly lost to future generations.

Students also learn that Milgram’s research was ethically dubious because it deceived people into behaving badly and that nothing like it would be permitted today. What need, then, is there to dust off the primary source? With a million other things to read, who has the time?

Still procrastinating, however, Dom found the time and it led him to a fascinating new discovery.16 Milgram ran a variety of different obedience studies. In each study, he manipulated a different feature of the situation to try to figure out what factors affected rates of obedience. He found that increasing the physical closeness of the person being shocked decreased obedience. He found that women responded in much the same way as men. He also found that having the experimenter issue instructions over the telephone reduced obedience, although some participants felt the need to lie and tell the absent experimenter that they had continued to deliver shocks to the hapless learner.

Milgram’s book provided the raw data for many of these studies. A table indicated the number of people who had stopped participating at every voltage point, from 15 volts all the way up to 450. As Dom read about each variant of the study, his eyes were increasingly drawn to these data and, in particular, to the disobedient participants. He was fascinated by those people who had withdrawn before they reached the final 450-volt shock—the people who had dissented in the face of a cruel authority figure. Who were these moral rebels?

To Dom’s surprise, he began to see a pattern to this disobedience. Milgram’s book made no mention of this pattern, and Dom had not heard anyone talk about it before. Were his eyes deceiving him? It took a matter of minutes to enter data from several of Milgram’s studies into a spreadsheet and plot them on a graph. He turned to Jay, seated right behind him in their office, and asked, “Am I seeing this right?”

In each experiment, there were twenty-nine points in time at which a participant could disobey the experimenter, ranging from 15 volts on the very first trial to 435 volts on the penultimate one. Yet when Dominic looked at the data closely, the points at which participants had actually disobeyed were not uniformly or randomly arrayed across these possibilities. Rather, disobedience seemed to peak at particular times and at one especially: a key moment of truth seemed to have occurred when it was time to deliver a shock of 150 volts.

What was so special about 150 volts? Why was this point in the study different from 135 volts or 165 volts? Dominic scrambled back to find the original methods to figure it out.

As we noted earlier, the learner in Milgram’s studies followed a script, uttering an escalating series of complaints, pleas, and expressions of pain to every participant as the shocks increased. His expressions of pain grew in intensity until he eventually fell silent.

But the 150-volt point was qualitatively different. It was the first (but not the last) time at which the learner asked specifically to be released from the experiment. He shouted, “Experimenter, get me out of here! I won’t be in the experiment anymore! I refuse to go on!”

This first request was a turning point. Participants faced a crucial choice: either they listened to and complied with the wishes of the learner or they obeyed the instructions of the experimenter, in which case they would probably continue all the way to the end.

Similar requests by the learner as the study progressed did not have this same effect. It was the first one that really mattered. And although the learner’s expressions of pain continued to grow as the shocks increased, rates of disobedience were unaffected, suggesting that the decision to stop shocking a fellow human being was not driven by empathic reactions to their suffering. Something else was going on.

So what did drive their decisions? A recent analysis by Steve Reicher, Alex Haslam, and Joanne Smith suggests that experiencing a sense of shared identity, either with the experimenter or with the learner, likely played a key role in participants’ choices.17 And it was at the 150-volt mark that participants had to choose a side: Whose team were they on, the experimenter’s or the learner’s?

The inability to directly replicate Milgram’s research has stymied many an investigation, but this trio of researchers came up with a clever workaround. Half a century after the original research, they told participants, including a group of expert psychologists and a group of undergraduates, about different versions of Milgram’s experiments. For each variant of the experiment, they asked these participants to rate how much they thought they would identify with the scientist and scientific community versus the learner as a member of the general public.

People thought that they would identify more with the experimenter and less with the learner in some variants of Milgram’s studies, such as when the learner was physically remote. For other versions, they thought the opposite, such as when the experimenter was literally phoning it in.

Taking these current-day ratings of identification, the researchers tested whether they could predict what the actual, real participants in the original experiments had done back in the 1960s. And they could! Current-day participants’ beliefs that they would identify with the experimenter strongly predicted greater obedience in the original Milgram experiments conducted five decades earlier. In contrast, their beliefs that they would identify with the learner strongly predicted less obedience in the original studies.

Obedience and disobedience, then, both seem to be a matter of identity. Whose side are you on? Are you with the scientist in the lab coat, with all that he represents about knowledge, progress, and expertise? Or are you with the member of the public, with all the rights of a fellow citizen? Once people made this decision, it shaped their willingness to engage in dissent or continue along the path to cruelty.





Rational Conformity and Irrational Dissent


Shortly after Dom published his analysis of Milgram’s obedience data, he met Bert Hodges. Hodges and his colleagues had just flipped the script on Solomon Asch’s famous line-perception experiments.18 In the original studies in the 1950s, participants clearly saw the correct answers on a visual task but heard everyone else get them wrong, which led them to conform. In this new version, the study was set up so that participants could hear other people’s answers, but they could not clearly see the task themselves. Participants had to identify words projected onto a screen at the front of the room, but they were seated in such a way that it was difficult to make out the right answer. As in Asch’s studies, other participants—who could clearly see the words—responded first.

Imagine yourself in the shoes of the participant. Through no fault of your own, you cannot see well enough to properly complete the task. Fortunately, however, other people can and they are answering ahead of you. What would you do? While conforming to obviously incorrect answers in Asch’s original study was uncomfortable, here, conforming to other people’s presumably correct answers would make perfect sense. In good conscience, you can sit back, relax, and go along with the crowd.

And that is what participants did about two-thirds of the time. But on the other trials, they did something counterintuitive: they guessed and made up an answer that was almost certainly wrong. Approximately one-third of the time, people chose not to draw upon the information they received from more knowledgeable others. Strikingly, this proportion of “irrational” nonconformist behavior was almost the same as the proportion of “irrational” conformist behavior in the original study, which also occurred about one-third of the time.

But the behaviors of people in both Asch’s original and the inverted conformity studies are irrational only if we assume that people are motivated by one goal and one goal alone: the desire to be accurate. Clearly they are not. Asch’s original participants were also motivated by the goal of fitting in, being liked and accepted by others. But this goal too was not so all-consuming that people conformed all of the time.

People possess numerous goals. They are almost always trying to accomplish more than one thing at a time, and the actions they choose to take often reflect an attempt to balance among them. When you are with other people, you strive to be a good social partner, and when you are in a group, you aim to be a solid, contributing, and useful member. There are multiple ways to do this. Being accurate and providing correct information is important. But so is establishing friendly and trusting relationships, and so is telling the truth about who you are, in a broader sense than simply giving the objectively right answer.

Everyone has been in this situation. You are sitting with friends, coworkers, or family members, and they all agree about something you know is utterly ridiculous. “Cats is a great movie!” “Eggnog is delicious and not a bit cloying!” “Cabbots are what happens when a cat mates with a rabbit—and they really exist!” But as the righteous urge to correct your compatriots bubbles up, you push it back down. Let’s keep the peace, you think. You are having a good time; you can set the record straight later. Your broader truth is I am here, I am one of you, and I want to make this thing with all of you work.

This is what participants in Asch’s original experiments were doing: balancing between goals. They were walking a tightrope between giving accurate answers that put them at odds with others and giving accommodating responses that signaled a willingness to play along to maintain good standing in the group. In the inverted version of the experiment, a different tightrope act took place. Here, people sought to balance between being accurate—which in this case meant mirroring the responses of others—and making unique contributions to the group. As much as standing out from the crowd can be uncomfortable, we do not like to feel that we are mindlessly copying others all of the time either. By diverging once in a while, participants could maintain a degree of independence and also signal to others that they were not to be relied on as good sources of information, a useful acknowledgment when their view was obscured.

These studies reveal some critical lessons about human nature. First, people are not blindly obedient to authorities. Resistance and dissent are as much a part of human nature as conformity. Instead, what matters is who we identify with: are we aligned with those in positions of authority or with more ordinary people whose wishes and rights we think should be heard and taken into account?

Second, people are not inevitably sheeplike in the face of pressure from their peers. We do, it is true, frequently conform to the behavior of others, and for good reasons. But we also often have good reasons not to conform. When we choose to deviate, it is usually not because we do not care what others think or because we want to be difficult. We usually deviate because we want to be useful to our groups.

Groups tend to make better decisions when people can express divergent views. A little bit of dissent can inject a vital piece of new information, broaden people’s thinking, or make it more comfortable for others to speak up. And sometimes dissent simply causes us to reassess assumptions one more time, confirming with a bit more confidence that we are on the right track.





The Choices We Face


So when will people do this important work? And how can groups, whether they are neighborhood coalitions, work organizations, or even nation-states, foster healthy levels of dissent?

Imagine a few scenarios. You are a border guard and you have noticed a tendency among your coworkers to question certain types of travelers more aggressively than others. Or you work for a midsize company and it is common practice for employees on your team to spend a couple of hours a day on social media instead of doing their jobs. Or you work for a small start-up firm where everyone from the boss on down competes to be the most hardworking, putting in very long days, coming in on weekends, and boasting about how busy they are. Or perhaps you are a member of a volunteer organization where folks are not shy about expressing their disdain for people who disagree with them politically, even though you know there are such people working diligently—and silently—among you.

To figure out what you might do in these sorts of situations, we can ask a series of questions. The first is quite simple: Do you disagree with the norm or are you okay with it? Perhaps you have never thought about it before—never asked yourself, for example, whether paying people to surf social media is a good use of your company’s resources. Or you have thought about the norm, but you do not have a problem with it. Some types of people should, you might believe, be questioned more intensively than others at the border. Or if people want to work long hours at your start-up firm, fine—it is up to them. If you do not disagree with the norm, you are probably not going to turn around and question it. If you do disagree, you might.

But then we need to ask a second question: How much do you identify with the group?19 Identification matters because it influences whose interests you are motivated to pursue. Even at the best of times, dissent is difficult; remember how people react to moral rebels. Dissent might not be worth the trouble unless you deeply care about the group, your fellow members, and your collective future.

Let’s say you are weakly identified with the group. In other words, you disagree with a norm in a group that you don’t particularly care for. Faced with this situation, do you invest your time and energy in dissenting? Do you expose yourself to the social flak that almost inevitably comes along with it? Probably not. In this case, you are quite likely to disengage further from the group. You might express your opinion to your outside friends, but not in the hope of changing anyone’s mind or making the group a better place. Depending on the gravity of your conflict with the norm, you might even quit entirely. Bye, suckers!

But what if this is a group that you do care deeply about? In this case, dissent might just be worth it. You are invested in the group and want it to succeed. You want it to be a well-regarded group, a successful group, an ethical and moral group. In this case, you might be motivated to challenge your group to try to change it for the better.

You worry that treating some travelers differently as they cross the border will undermine the public’s trust in border agents, undercut your effectiveness, or reduce morale. You think that some of your team’s recent performance woes could be solved if people focused a bit more on their jobs and less on posting selfies to Instagram or polishing their résumés on LinkedIn. You notice that the competitive “Who works the hardest?” culture at your start-up is burning out good people and weeding out certain kinds of folks, especially women with kids. You worry that this culture is not sustainable in the long run and undercuts your ability to retain the best talent. Or within your highly dedicated volunteer organization, you believe it is important as a matter of principle that people who think differently should nevertheless be treated with respect.

When you see a problem and care about the group, whether you are likely to actually dissent depends on the answer to a third question: What do you expect the consequences of dissent to be? There are two types of potential consequences that matter: those affecting you as an individual and those affecting the group as a whole.

Consequences for the individual are important. As we have seen, deviance is often met with negative reactions, reactions that can sting all the more when they come from close compatriots in a beloved group. Your devotion to the group may be enough for you to risk sacrificing the goodwill and acceptance of others, but as the severity of personal sanctions increases, so too will your discomfort and disinclination to speak out. Consequences for the group really start to matter now. If you think that, despite a negative reception, your dissent has a reasonably good chance of changing the group—of actually making things better—you might still go for it. But if you sense that achieving change is unlikely or impossible, dissenting may seem, quite simply, not worth it. This is the cost-benefit analysis of dissent.

We can draw the route to your likely decision through a series of forking paths. First fork: Do you disagree with the norm? Second fork: Are you strongly identified with the group? Third fork: Do the potential benefits of dissent outweigh the potential costs? If the answer to all of these questions is yes, you are quite likely to dissent.





Inspiring Dissent


We celebrate dissenters and critics as heroes in the abstract or when we can hold them at a distance. We also like to think of ourselves as the kind of people who would bravely speak out when they notice wrongdoing or think there is a better way of accomplishing things. But research suggests that when confronted with actual dissenters—with moral rebels—people are often discomfited and react by derogating or rejecting them. And when they encounter substantive disagreements with their groups, people often remain silent or distance themselves rather than summoning the courage to try to change things for the better.

If group members or leaders want to do something about this state of affairs, want to create cultures where people speak up when something is wrong, what should they do? If we hope to foster groups in which people are free to express their perspectives and have the capacity to learn from divergent views, how could we go about it?

In some of our research we have focused on the first fork in the road by simply asking people to think about ways in which norms might be harmful to their groups.20 Once we got people to think about these problems, strongly identified members were more willing to express dissenting views. In fact, they were more willing to dissent than both weakly identified members and strongly identified members who had thought about how a norm was harmful to themselves personally.

The key to dissent was that they saw the harm to a group that they cared about.

We have also tested more subtle ways of prompting people to think critically about what their groups are up to.21 In particular, getting people to think more abstractly seems to open them up to divergent thoughts about group behavior. There are different ways of getting people to think abstractly, but a common one is to encourage longer-term as opposed to shorter-term thinking. When we think in the short term, we focus on immediate needs and goals. Often this involves a sense of urgency—We just need to get this done—and the feeling that now is not the time to raise questions or doubts.

When we think in the longer term, however, we become more attentive to the possibility of change and improvement. Thinking five or ten years down the road raises the question “Do we still want to be doing this then?” Will we be able to make the transition from start-up to profitable company if we keep burning people out with crazy work hours? Will today’s national security concerns be the same tomorrow and, if not, how will we repair relations with communities if we damage them with disparate treatment now? If we cannot get employees to spend less time online and more time doing their jobs, will we even exist in five years? Is political bias within our volunteer organization driving away dedicated contributors and will it undermine our credibility?

To investigate the role of time in dissent, we studied supporters of the Republican Party and their willingness to challenge popular positions within their party.22 In one case, for example, we asked people whether they would be willing to publicly express concern about the Republican Party’s opposition to the Affordable Care Act, also known as Obamacare.

Three things mattered in terms of their willingness to speak out. First, as we have discussed, they had to disagree with the standard party position—and some did. Second, they had to be strongly identified with the Republican Party. And third, they had to be worried about the future consequences for the Republican Party itself. In this case, they had to be concerned that opposition to publicly funded health care would hurt the party’s prospects in future elections. When these three things lined up, we observed greater willingness to dissent.

To aspiring change agents, we would suggest a couple of things. The first is that it is okay to be weakly identified with a group. Not every group you are a part of is necessarily worth identifying with. We think, for example, that it was a good thing when participants in Milgram’s experiments did not identify with the experimenter. This lack of identification with authority and identification with the learner instead led people to do the right thing and disobey harmful instructions.

Second, in order to be in a position to dissent at all, you have to be able to think critically about what your group is doing. You have to experience some sort of disagreement. This sounds simple, but it is not. If everyone spends time on social media at work, it becomes a default or habit. It is just how things are done, and you might never give it a second thought. If everyone works insane hours, it might not seem insane; it’s just the reality of how we work. By the time these norms become problematic, many people within the group have rationalized and internalized them, thinking that if they do not work long hours, the company will go bankrupt or the team will surely fail.

Sometimes bad patterns develop and worsen with the same logic that led Milgram’s participants to shock someone (or so they believed) with 450 volts. A 15-volt shock does not seem too bad. People can rationalize it and comfortably up the voltage to 30 volts, then 45 volts, and so on. Each small step makes the next step easier. Once they get past the 150-volt mark, they are likely to just continue going all the way up to 450 volts. What had once seemed unthinkable becomes routine.

When the potential downsides to group norms are pointed out, however, many people can immediately see them, although they may not have noticed them spontaneously themselves. To do so requires a broadening of focus from the immediate present or task to the future or the larger meaning of things. This may be why dissent tends to be greater among people who score higher on the personality trait of openness to experience.23 People who are highly open tend to think about things in more creative and abstract ways, making more connections between disparate thoughts. They also tend to seek out more unique experiences, which may expose them to divergent perspectives.

If you are in a group with which you are weakly identified, it is worth paying attention when you observe yourself conforming in ways that make you uncomfortable. You do not usually feel like you have to work on weekends, but you do when the regional manager is in town. You generally do not make fun of others who disagree with you politically, but somehow you find yourself doing so in the company of your colleagues. These shifts in behavior are a signal that you are not indifferent to the norm; that, in fact, you might have a problem with it. Feeling compelled to change your actions from what you would normally do can be a sign that something is amiss.

Hopefully, though, you get to spend most of your time in groups that you care about and identify with. Here, you are motivated to do what you believe is in the group’s best interests and you want to do right by the group. But what is in the group’s best interests? And what does it mean to do right by the group? Those are the key questions.

If, as a leader, you want to encourage people to dissent more often when they see a problem and avoid a culture of groupthink, your levers reside at the forks in the decision-making road we have described. People need to think critically enough to experience disagreement. They need to identify strongly with the group and care enough to speak up. And, of course, people need to think that the consequences of dissent make it worthwhile. If the likely costs are too high or the likely benefits are too low, dissent is unlikely.

Get people thinking longer term about what your group is trying to do. In organizations, if the boss is interested predominantly in short-term outcomes or if management jumps from immediate crisis to immediate crisis, employees will adopt the same focus. They will feel they have to. However, if every once in a while, leaders stop to ask about longer-term consequences or about where people want to be in ten years, others will feel licensed to think in that way as well. An obsession with quarterly returns might be one of the most powerful incentives promoting groupthink and undercutting dissent—and a similar dynamic may affect politicians stuck in perpetual election cycles.

Leaders should be especially attentive to the signals they send about the costs of dissent. As much as people can be reluctant to deviate from peers, the pressure to keep one’s mouth shut is often greater in hierarchical situations and when the boss is around. People are more willing to speak up in groups and organizations when they believe that offering divergent ideas and opinions is not risky and especially if it is explicitly valued. Leaders at all levels play a key role in creating these feelings of “psychological safety.”24

Organizational psychologist Amy Edmondson studied how leaders promoted psychological safety in cardiac operating teams as they learned a new way of conducting heart surgery.25 This new surgical technique required that these teams, composed of surgeons, anesthesiologists, nurses, and technicians, work as perfectly coordinated units despite big differences in training, disciplinary backgrounds, and certainly status. And the stakes were incredibly high—their ability to communicate was literally a matter of life and death.

She observed that surgical teams where members had a voice and felt comfortable speaking up were more successful at adopting the new lifesaving technique. She found that some surgeons, the team leaders, were better at creating this type of psychological safety than others. The leaders of more successful teams invested more energy communicating the importance of their mission—learning the new technique. But they also worked harder to reduce power disparities within their teams, trying to put everyone on something closer to an equal footing. When others had things to say, these leaders made sure to listen and take action. They took care to highlight the importance of every person’s role, and they demonstrated humility by noting their own limitations. They also avoided overreacting to errors, often choosing to adapt and move on when a team member made a mistake rather than calling the individual out.

A similar pattern was observed at Google. They set out to determine what factors made for the most effective teams.26 They looked at 180 teams from across the company to identify skill sets or personality types that accounted for group success. Google is famous for crunching data and finding patterns—but there were virtually no patterns to be found. According to Abeer Dubey, one of the leaders of Project Aristotle (as the study was known): “We had lots of data, but there was nothing showing that a mix of specific personality types or skills or backgrounds made any difference. The ‘who’ part of the equation didn’t seem to matter.”

But one thing did predict team success. The research team at Google concluded that group dynamics were actually the key to team success. In particular, their data revealed that psychological safety, more than anything else, was critical to making a team effective. The best teams provided a supportive environment in which people could voice alternative perspectives without fear of negative consequences.

People often think that psychological safety means you cannot criticize at all. But what it actually means is quite the opposite—psychologically safe environments are ones in which people feel safe expressing divergent perspectives because debate is welcomed and embraced. These are groups where people can disagree respectfully and come back together the next day without hard feelings. They can challenge ideas and practices because all the members feel like they are working toward the same goals.

Smart leaders and organizations focus on cultivating environments where people feel psychologically safe and on reducing the costs associated with dissent. Some organizations have gone even further and found ways to reward constructive dissent. The American Foreign Service Association exemplifies this ethos. Every year, it gives four “Constructive Dissent Awards,” cosponsored with the director general of the Foreign Service, to actively serving personnel. As the website states:

The awards publicly recognize individuals who have demonstrated the intellectual courage to challenge the system from within, to question the status quo and take a stand, no matter the sensitivity of the issue or the consequences of their actions.27



By clearly recognizing the value of dissent for the institution—and, by proxy, the nation as a whole—the organization increases the rewards associated with taking these sorts of actions. It also helps that each award comes with a four-thousand-dollar prize on top of the recognition!

Of course, most of us are not in a position to create awards for constructive dissent. But we are still a crucial part of the equation simply as ordinary group members. How we react to divergent perspectives, whether we are willing to listen, and how we treat the person expressing a unique opinion shapes dissenters’ willingness to carry on. It probably also affects the future behavior of other people who are paying attention to what happens. While our natural inclinations are often to resist counter-normative actions and actors, we know that these things are often good for our groups and that they frequently come from people who do, in fact, care.

So take a deep breath and, rather than jumping immediately to conclusions about nefarious motives, give dissenters, critics, and rebels a chance. There is a good possibility, as the American Foreign Service Association recognizes, that they intend to be constructive.

But ultimately, who cares what their motives are? As research on the effects of deviance and dissent shows, one of the major benefits of dissent is that it gets the rest of us thinking. The dissenter does not have to be right to invigorate our thinking and increase the chances that we will make better and more innovative decisions. Having a devil’s advocate on your team could benefit everyone.

If we understand that dissent is good for our groups, we may be more receptive to it. But sometimes that might not be enough. You might be nodding along to our suggestions, but think back to the studies on moral rebels at the beginning of this chapter. People were resistant to others who deviated on matters of principle when they themselves had not done so because they felt it called into question their own wisdom and integrity. To avoid this threat to self-image, participants in these studies downplayed and disparaged the rebels, calling them “self-righteous” and “confused.”

Thankfully, Benoît Monin and colleagues have found a potential antidote to this less-than-helpful reaction. They found that reminding participants of recent experiences in which they exhibited behaviors consistent with values that they held dear reduced the threat posed by a moral rebel.28 This affirmation exercise reminded people that they often were, in fact, wise and good, and it seemed to free them to see the wisdom and goodness in others, even when they themselves may not have behaved as well as they could have in that particular moment.

Here is how Monin and colleagues affirmed their participants:

Please write about a recent experience in which you demonstrated a quality or value that is very important to you and which made you feel good about yourself. Examples might include (but are not limited to) artistic skills, sense of humor, social skills, spontaneity, athletic ability, musical talent, physical attractiveness, creativity, business skills, or romantic values.



You can try it now if you like or, better yet, the next time you do not want to hear what a troublemaker or rabble-rouser has to say. And with any luck, as time goes on, some of the experiences you will be proud to write about will include providing room for others to dissent and engaging in a bit of righteous rebellion yourself.
